{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "#import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Encode a text inputs\n",
    "text = \"Who was Jim Henson ? Jim Henson was a\"\n",
    "indexed_tokens = tokenizer.encode(text)\n",
    "\n",
    "# Convert indexed tokens in a PyTorch tensor\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "# Set the model in evaluation mode to deactivate the DropOut modules\n",
    "# This is IMPORTANT to have reproducible results during evaluation!\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "tokens_tensor = tokens_tensor.to('cuda')\n",
    "model.to('cuda')\n",
    "\n",
    "# Predict all tokens\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "    predictions = outputs[0]\n",
    "\n",
    "# get the predicted next sub-word (in our case, the word 'man')\n",
    "predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "predicted_text = tokenizer.decode(indexed_tokens + [predicted_index])\n",
    "\n",
    "predicted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator:\n",
    "    def __init__(self):\n",
    "        # Load pre-trained model tokenizer (vocabulary)\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        # Load pre-trained model (weights)\n",
    "        self.model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "        # Set the model in evaluation mode to deactivate the DropOut modules\n",
    "        # This is IMPORTANT to have reproducible results during evaluation!\n",
    "        self.model.eval()\n",
    "        # If you have a GPU, put everything on cuda\n",
    "        self.model.to('cuda')\n",
    "\n",
    "    \n",
    "    def generate_word(self, start_text):\n",
    "        \"\"\"\n",
    "        Generate one word (or sub-word, sometimes) to add onto some start text.\n",
    "        The generated word will contain a leader space if appropriate.\n",
    "        \"\"\"\n",
    "        # Encode text inputs\n",
    "        indexed_tokens = self.tokenizer.encode(start_text)\n",
    "        # Convert indexed tokens in a PyTorch tensor\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        # Move the tokens to the GPU.\n",
    "        tokens_tensor = tokens_tensor.to('cuda')\n",
    "        \n",
    "\n",
    "        # Predict all tokens\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(tokens_tensor)\n",
    "            predictions = outputs[0]\n",
    "\n",
    "        # get the predicted next sub-word.\n",
    "        predicted_index = torch.argmax(predictions[0, -1, :]).item()\n",
    "        generated_word = self.tokenizer.decode(predicted_index)\n",
    "        return generated_word\n",
    "    \n",
    "    def generate(self, start_text, word_count=7):\n",
    "        text = start_text\n",
    "        for _ in range(word_count):\n",
    "            text += self.generate_word(text)\n",
    "        return text\n",
    "    \n",
    "    def generate_sentence(self, start_text):\n",
    "        text = start_text\n",
    "        sentence = ''\n",
    "        while (True):\n",
    "            word = self.generate_word(text)\n",
    "            text += word\n",
    "            sentence += word\n",
    "            if '.' in word:\n",
    "                break\n",
    "        return sentence\n",
    "\n",
    "gen = TextGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' far'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate_word(\"Can't stop now; I've travelled so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Can't stop now; I've travelled a lot. I've been to a lot of\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate(\"Can't stop now; I've travelled\",  10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Can't stop now; I've travelled a lot. I've been to a lot of\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.generate(\"Can't stop now; I've travelled\",  10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My assignment was to wash the dishes.  I couldn't do that because I was too busy.               \""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = gen.generate(\"My assignment was to wash the dishes.  I couldn't do that because\",20)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My assignment was to wash the dishes.  I couldn't do that because I was too busy.               I feel terrible about that because I didn't do it. \""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text += \"I feel terrible about that because\"\n",
    "gen.generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlameModeMe:\n",
    "    my = 'my'\n",
    "    i = 'I'\n",
    "\n",
    "class BlameModeYou:\n",
    "    my = 'your'\n",
    "    i = 'you'\n",
    "\n",
    "class BlameModeTeam:\n",
    "    my = 'our'\n",
    "    i = 'we'\n",
    "\n",
    "class BlameModeTeamBlameShift:\n",
    "    my = 'their'\n",
    "    i = 'they'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTRO_TEXT = [\n",
    "    '[my] assignment was to',\n",
    "    '[I] was supposed to',\n",
    "    '[I] intended to',\n",
    "    '[my] goal was to',\n",
    "    '[my] dream, [my] destiny was to',\n",
    "    '[I] had every intention to'\n",
    "]\n",
    "\n",
    "HOWEVER_TEXT = [\n",
    "    \"Sadly, that didn't work out because\",\n",
    "    \"Unfortunately, there was a serious problem with that\",\n",
    "    \"[I] couldn't do that because\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Unfortunately, there was a serious problem with that'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(HOWEVER_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You know that I would never do that'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'You know that [I] would never do that'.replace('[I]', 'I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcuseSituation:\n",
    "    def __init__(self, text_generator, assignment, tasks=[], is_team=False, blame_others=False):\n",
    "        self.assignment = assignment\n",
    "        self.tasks = tasks\n",
    "        self.generator = text_generator\n",
    "        if is_team:\n",
    "            if blame_others:\n",
    "                mode = BlameModeTeamBlameShift\n",
    "            else:\n",
    "                mode = BlameModeTeam\n",
    "        else:\n",
    "            if blame_others:\n",
    "                mode = BlameModeYou\n",
    "            else:\n",
    "                mode = BlameModeMe\n",
    "        self.mode = mode\n",
    "    \n",
    "    def generate_excuse(self):\n",
    "        # Lead-in text, setting up the situation.\n",
    "        background = [random.choice(INTRO_TEXT), self.assignment, '.']\n",
    "        background += [random.choice(HOWEVER_TEXT)]\n",
    "        \n",
    "        background_text = self._list_to_text(background)\n",
    "        text = self.generator.generate_sentence(background_text)\n",
    "        return background_text + text\n",
    "\n",
    "    def generate_excuses(self, count=5):\n",
    "        result = []\n",
    "        for _ in range(count):\n",
    "            result.append(self.generate_excuse())\n",
    "        return result\n",
    "            \n",
    "    def _list_to_text(self, chunk_list):\n",
    "        words = []\n",
    "        for entry in chunk_list:\n",
    "            entry = entry.replace('[I]', self.mode.i)\n",
    "            entry = entry.replace('[my]', self.mode.my)\n",
    "            words.append(entry)\n",
    "        return ' '.join(words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"my goal was to prepare a nice dinner for you for Valentine's day . Unfortunately, there was a serious problem with that.\",\n",
       " \"I was supposed to prepare a nice dinner for you for Valentine's day . Unfortunately, there was a serious problem with that.\",\n",
       " \"I had every intention to prepare a nice dinner for you for Valentine's day . Unfortunately, there was a serious problem with that.\",\n",
       " \"my assignment was to prepare a nice dinner for you for Valentine's day . I couldn't do that because I was too busy with my work and my family.\",\n",
       " \"my goal was to prepare a nice dinner for you for Valentine's day . Sadly, that didn't work out because I was too busy with my family and my work.\"]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ExcuseSituation(gen, assignment=\"prepare a nice dinner for you for Valentine's day\", tasks=[\n",
    "    'plan the menu',\n",
    "    'go to the grocery store to buy the ingredients',\n",
    "    'cook it up',\n",
    "    'plate the meal in an attractive way',\n",
    "])\n",
    "s.generate_excuses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
